### Starting TaskPrologue of job 755842 on a1621 at Thu Jun  8 13:04:34 CEST 2023
Running on cores 96-111 with governor ondemand
Thu Jun  8 13:04:34 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A40                      On | 00000000:C1:00.0 Off |                    0 |
|  0%   30C    P8               21W / 300W|      0MiB / 46068MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
### Finished TaskPrologue

2023-06-08 13:04:45.394876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Reading pretrained model and tokenizer
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/atuin/b114cb/b114cb13/GPT2_RFP_1/GPT2_denovo_zymlike.py", line 76, in <module>
    sequences = main(label, model, special_tokens, device, tokenizer, protgpt2)
  File "/home/atuin/b114cb/b114cb13/GPT2_RFP_1/GPT2_denovo_zymlike.py", line 31, in main
    outputs = protgpt2(
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/pipelines/text_generation.py", line 209, in __call__
    return super().__call__(text_inputs, **kwargs)
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/pipelines/base.py", line 1109, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/pipelines/base.py", line 1115, in run_single
    model_inputs = self.preprocess(inputs, **preprocess_params)
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/pipelines/text_generation.py", line 213, in preprocess
    prefix + prompt_text, padding=False, add_special_tokens=False, return_tensors=self.framework
TypeError: can only concatenate str (not "Tensor") to str
=== JOB_STATISTICS ===
=== current date     : Thu Jun  8 13:05:36 CEST 2023
= Job-ID             : 755842 on alex
= Job-Name           : GPT2_denovo.sh
= Job-Command        : /home/atuin/b114cb/b114cb13/GPT2_RFP_1/GPT2_denovo.sh
= Initial workdir    : /home/atuin/b114cb/b114cb13/GPT2_RFP_1
= Queue/Partition    : a40
= Slurm account      : b114cb with QOS=normal
= Requested resources: cpu=16,mem=60000M,node=1,billing=16,gres/gpu=1,gres/gpu:a40=1 for 1-00:00:00
= Elapsed runtime    : 00:01:03
= Total RAM usage    : 7.9 GiB of assigned 58 GiB (13.6%)   
= Node list          : a1621
= Subm/Elig/Start/End: 2023-06-08T13:04:33 / 2023-06-08T13:04:33 / 2023-06-08T13:04:33 / 2023-06-08T13:05:36
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           28.8G    52.4G   104.9G        N/A      98K     500K   1,000K        N/A    
    /home/vault          5.9G   524.3G  1048.6G        N/A      10      200K     400K        N/A    
    /lustre              4.0K     0.0K     0.0K        N/A       1   20,000      250K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
