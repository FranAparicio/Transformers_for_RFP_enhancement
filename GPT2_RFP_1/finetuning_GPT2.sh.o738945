### Starting TaskPrologue of job 738945 on a0226 at Wed May 17 14:44:26 CEST 2023
Running on cores 96-111 with governor ondemand
Wed May 17 14:44:26 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A40                      On | 00000000:C1:00.0 Off |                  Off |
|  0%   31C    P8               21W / 300W|      0MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
### Finished TaskPrologue

2023-05-17 14:44:34.123652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
05/17/2023 14:44:38 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
slurmstepd: error: *** JOB 738945 ON a0226 CANCELLED AT 2023-05-17T14:44:43 ***
=== JOB_STATISTICS ===
=== current date     : Wed May 17 14:44:45 CEST 2023
= Job-ID             : 738945 on alex
= Job-Name           : finetuning_GPT2.sh
= Job-Command        : /home/atuin/b114cb/b114cb13/GPT2_RFP_1/finetuning_GPT2.sh
= Initial workdir    : /home/atuin/b114cb/b114cb13/GPT2_RFP_1
= Queue/Partition    : a40
= Slurm account      : b114cb with QOS=normal
= Requested resources: cpu=16,mem=60000M,node=1,billing=16,gres/gpu=1,gres/gpu:a40=1 for 1-00:00:00
= Elapsed runtime    : 00:00:18
= Total RAM usage    : 0.4 GiB of assigned 58 GiB (0.7%)   
= Node list          : a0226
= Subm/Elig/Start/End: 2023-05-17T14:44:24 / 2023-05-17T14:44:24 / 2023-05-17T14:44:25 / 2023-05-17T14:44:43
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           28.5G    52.4G   104.9G        N/A      98K     500K   1,000K        N/A    
    /home/vault          5.9G   524.3G  1048.6G        N/A      10      200K     400K        N/A    
    /lustre              4.0K     0.0K     0.0K        N/A       1   20,000      250K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
