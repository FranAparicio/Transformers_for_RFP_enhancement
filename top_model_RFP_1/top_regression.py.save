# Loading the dataset
import pandas as pd
import numpy as np
import ast
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

model = linear_model.LinearRegression()

# Parameters to establish
data_df = pd.read_csv("RFPs3nms_embed.csv")
column_of_interest = "states.0.qy"
average_pooling = "YS" # Check "YES" if want to do it, other value if want to use [CLS] instead
mask = "YS" # To mask the outliers, value depends on the column of interest
min_mask = 0
max_mask = 1
model = linear_model.Ridge(alpha=.5)
""" Options
linear_model.LinearRegression() # Ordinary least squares
Linear_model.LinearRegression(positive=True) # Non-negative least squares (condition extrapolable to other models)
linear_model.Ridge(alpha=.5) # Ridge regression
etc.
"""

# Dropping those rows which have a missing value for the column of interest
print("Shape before dropping:")
print(data_df.shape)
data_df.dropna(subset=[column_of_interest], inplace=True)
print("Shape after dropping:")
print(data_df.shape)

# Defining X and Y
X = data_df["embedding"].values
new_X = []
for x in X:
	arr = ast.literal_eval (x)
	if average_pooling == "YES":
		avg_token_embedding = np.mean(arr, axis=0)
		new_X.append(avg_token_embedding)
	else:
		CLS_token_index = 0
		new_X.append(arr[CLS_token_index])
X = np.array(new_X)
# np.save("X_values.npy", X) # To store value for faster processing uncomment
# np.load("X_values.npy") # To use stored value uncomment

Y = data_df[column_of_interest].values

# Splitting the dataset into training and test sets
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=41)
print("shape of the train - test, X - Y values:")
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

# Train the linear regression model
model.fit(X_train, Y_train)

# Predict the test set results
Y_pred = model.predict(X_test)
print("Y predictions:")
print(Y_pred)

"""
We could also use:
model.predict([[14.96,14.76,...,199.43,17.43]])
To predict a specific example
"""

# Filter outliers
if mask == "YES":
	mask = np.logical_and(Y_pred >= min_mask, Y_pred <= max_mask) # This is for QY, change as appropriate
	Y_test_filtered = Y_test[mask]
	Y_pred_filtered = Y_pred[mask]
	Y_test = Y_test_filtered
	Y_pred = Y_pred_filtered

# Evaluate the model
mse = mean_squared_error()

print('Coefficients:', model.coef_)
print('Intercept:',model.intercept_)
print('Mean squared error (MSE): %.2f' % mean_squared_error(Y_test, Y_pred))
print('Coefficient of determination (R^2): %.2f' % r2_score(Y_test, Y_pred))

# Scatter plots
import matplotlib.pyplot as plt

plt.scatter(Y_test, Y_pred, alpha=0.5)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.show()

# Predicted values
pred_Y_df=pd.DataFrame({'Actual Value':Y_test,'Predicted Value':Y_pred,'Difference':Y_test-Y_pred})
print(pred_Y_df[0:20])

