### Starting TaskPrologue of job 755339 on a1722 at Wed Jun  7 15:15:52 CEST 2023
Running on cores 112-127 with governor ondemand
Wed Jun  7 15:15:52 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A40                      On | 00000000:E1:00.0 Off |                    0 |
|  0%   29C    P8               21W / 300W|      0MiB / 46068MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
### Finished TaskPrologue

Reading pretrained model and tokenizer
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/atuin/b114cb/b114cb13/CTRL_RFP_1/generation_CTRL.py", line 74, in <module>
    sequences = main(label, model, special_tokens, device, tokenizer)
  File "/home/atuin/b114cb/b114cb13/CTRL_RFP_1/generation_CTRL.py", line 32, in main
    input_ids = tokenizer.encode(label,return_tensors='pt').to(device)
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2301, in encode
    encoded_inputs = self.encode_plus(
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2709, in encode_plus
    return self._encode_plus(
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py", line 176, in _encode_plus
    return super()._encode_plus(*args, **kwargs)
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 500, in _encode_plus
    batched_output = self._batch_encode_plus(
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py", line 166, in _batch_encode_plus
    return super()._batch_encode_plus(*args, **kwargs)
  File "/home/hpc/b114cb/b114cb13/.env/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 428, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
=== JOB_STATISTICS ===
=== current date     : Wed Jun  7 15:16:06 CEST 2023
= Job-ID             : 755339 on alex
= Job-Name           : generation_CTRL.sh
= Job-Command        : /home/atuin/b114cb/b114cb13/CTRL_RFP_1/generation_CTRL.sh
= Initial workdir    : /home/atuin/b114cb/b114cb13/CTRL_RFP_1
= Queue/Partition    : a40
= Slurm account      : b114cb with QOS=normal
= Requested resources: cpu=16,mem=60000M,node=1,billing=16,gres/gpu=1,gres/gpu:a40=1 for 10:00:00
= Elapsed runtime    : 00:00:14
= Total RAM usage    : 0.0 GiB of assigned 58 GiB (0.0%)   
= Node list          : a1722
= Subm/Elig/Start/End: 2023-06-07T15:15:52 / 2023-06-07T15:15:52 / 2023-06-07T15:15:52 / 2023-06-07T15:16:06
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           28.8G    52.4G   104.9G        N/A      98K     500K   1,000K        N/A    
    /home/vault          5.9G   524.3G  1048.6G        N/A      10      200K     400K        N/A    
    /lustre              4.0K     0.0K     0.0K        N/A       1   20,000      250K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
